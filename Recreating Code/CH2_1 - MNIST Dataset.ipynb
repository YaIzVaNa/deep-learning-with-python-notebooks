{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2.1 - Deep Learning with Python - A look at the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset included in keras and get familiarized with the data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images,train_labels), (test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dimensions, exploring the dataset we can see its an array storing rgb values, size of images are 28x28 px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made a small visualization loop for the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "\n",
      "                                                        \n",
      "\n",
      "                                                        \n",
      "\n",
      "                                                        \n",
      "\n",
      "                                                        \n",
      "\n",
      "                        \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m         \n",
      "\n",
      "                \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m         \n",
      "\n",
      "              \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m           \n",
      "\n",
      "              \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                     \n",
      "\n",
      "                \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m   \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                     \n",
      "\n",
      "                  \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                             \n",
      "\n",
      "                      \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                           \n",
      "\n",
      "                      \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                           \n",
      "\n",
      "                        \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                     \n",
      "\n",
      "                          \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                   \n",
      "\n",
      "                            \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                 \n",
      "\n",
      "                              \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                 \n",
      "\n",
      "                                  \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m               \n",
      "\n",
      "                            \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m               \n",
      "\n",
      "                        \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                 \n",
      "\n",
      "                    \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                   \n",
      "\n",
      "                \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                     \n",
      "\n",
      "            \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                         \n",
      "\n",
      "        \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                             \n",
      "\n",
      "        \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m \u001b[0;22;40m \u001b[0m                                 \n",
      "\n",
      "                                                        \n",
      "\n",
      "                                                        \n",
      "\n",
      "                                                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(train_images[0]):\n",
    "    for j in i:\n",
    "        if j!=0:\n",
    "            print(\"\\x1b[0;22;40m \\x1b[0m\",end=' ')\n",
    "        else:\n",
    "            print(\" \",end=' ')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we build the deep neural network with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set loss function, optimizer and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping the data, making it one dimensional on the pixel domain, scaling RGB values from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images=train_images.reshape(60000,28*28)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=test_images.reshape(10000,28*28)\n",
    "test_images.shape\n",
    "test_images=test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do one-hot-encoding or turning into categorical values the labels for identifying the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: See how this increased the dimensionality to use a binary indicator to identify a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.2230 - accuracy: 0.9313\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0814 - accuracy: 0.9754\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0544 - accuracy: 0.9835\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0390 - accuracy: 0.9877\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0299 - accuracy: 0.9905\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0183 - accuracy: 0.9939\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0153 - accuracy: 0.9952\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0124 - accuracy: 0.9963\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0119 - accuracy: 0.9962\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0105 - accuracy: 0.9970\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0092 - accuracy: 0.9972\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0081 - accuracy: 0.9976\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0045 - accuracy: 0.9989\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0043 - accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26576789cf8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,train_labels, epochs=25, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 50us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18201259261865868 0.9843000173568726\n"
     ]
    }
   ],
   "source": [
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play around now. I made a list of handwritten digits on paint (with my handstyle), let's see if it can recognize them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG (28, 28) RGBA\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "im = Image.open(\"MNIST Testing 8c.png\")\n",
    "print(im.format, im.size, im.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None (28, 28) L\n"
     ]
    }
   ],
   "source": [
    "im = im.convert(\"L\")\n",
    "print(im.format, im.size, im.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA0klEQVR4nL2SoQ7CMBCGf8jE5BRB1u0lSAAFDgtucnKOOWqRKJBIHIaELCHpFpAI3mB9AypxPw46aCWcurvv/mvvcsD/rWUHCXYPT12iyHXoZil5V03afnldlMMCaWbBwPKrmx4N3EoAMLoR2sq+jKeez+YkyUo4YXTm6cClnXq/Oe/hckXHOWhKKpF71iCpBKIjmbvaotIwsxJx6IIAYAokmQ9iU8KrbO4oaLJwP3bBBybQu8XYrLafgwDdmmRNym8EQMgjSSWslH1DUQZsNX5uTz5iTHfhoE+/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x26529C80898>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "im_mtx=np.asarray(im)\n",
    "im_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(im_mtx, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert greyscale image into binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_mtx=[]\n",
    "for row,i in enumerate(im_mtx):\n",
    "    for col,j in enumerate(i):\n",
    "        #print(row,col,j)\n",
    "        dnn_mtx.append(j/255)\n",
    "        #else:\n",
    "         #   dnn_mtx.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dnn_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to numpy array and shape it so that it can be processed by dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_mtx=np.asarray(dnn_mtx)\n",
    "dnn_mtx=np.reshape(dnn_mtx, (1,784))\n",
    "dnn_mtx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict label using trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=network.predict(dnn_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.7646959703386e-13\n",
      "1 1.7945324046197975e-11\n",
      "2 3.138668939347785e-13\n",
      "3 4.656776266681595e-11\n",
      "4 3.2360042481738554e-13\n",
      "5 3.7184907930587485e-10\n",
      "6 1.4894759037265004e-09\n",
      "7 1.6820330635739143e-15\n",
      "8 100.0\n",
      "9 3.5625270637142104e-12\n"
     ]
    }
   ],
   "source": [
    "for idx,i in enumerate(res[0]):\n",
    "    print(idx,i*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** It seems the NN is not able to identify most of my handwritten digits!!! \n",
    "\n",
    "Things to observe:     \n",
    "  \n",
    " **1:** Neither thin line and thick line (no letter & b label) are identified correctly (YES, we are accounting for MNIST being black background, white numbers, we just invert the colors)  \n",
    " \n",
    " **2:** MNIST like images (c label) work better, but still unacceptable (1,4,6 failed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
